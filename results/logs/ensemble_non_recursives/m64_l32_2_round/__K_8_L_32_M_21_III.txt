+-----------------+----------------------+
| Python Version  |        3.6.5         |
+-----------------+----------------------+
| PyTorch Version |        1.0.0         |
+-----------------+----------------------+
|     Device      | Tesla V100-SXM2-16GB |
+-----------------+----------------------+
|      Cores      |          8           |
+-----------------+----------------------+
|      GPUs       |          1           |
+-----------------+----------------------+
|  CUDNN Enabled  |         True         |
+-----------------+----------------------+
|  Architecture   |  Recursive NN (x8)   |
+-----------------+----------------------+
|     Dataset     |       CIFAR10        |
+-----------------+----------------------+
|     Testing     |        False         |
+-----------------+----------------------+
|     Epochs      |         700          |
+-----------------+----------------------+
|   Batch Size    |         128          |
+-----------------+----------------------+
|  Learning Rate  |         0.01         |
+-----------------+----------------------+
|  LR Milestones  |        [550]         |
+-----------------+----------------------+
|     Layers      |          32          |
+-----------------+----------------------+
|     Filters     |          21          |
+-----------------+----------------------+
|    BatchNorm    |        False         |
+-----------------+----------------------+
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
Non Recursive ConvNet
Conv_Net(
  (act): ReLU()
  (V): Conv2d(3, 21, kernel_size=(8, 8), stride=(1, 1), padding=(3, 3))
  (P): MaxPool2d(kernel_size=4, stride=4, padding=2, dilation=1, ceil_mode=False)
  (W): ModuleList(
    (0): Conv2d(21, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): Conv2d(21, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (2): Conv2d(21, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): Conv2d(21, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): Conv2d(21, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (5): Conv2d(21, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (6): Conv2d(21, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): Conv2d(21, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): Conv2d(21, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): Conv2d(21, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): Conv2d(21, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): Conv2d(21, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (12): Conv2d(21, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): Conv2d(21, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (14): Conv2d(21, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): Conv2d(21, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (16): Conv2d(21, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (17): Conv2d(21, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): Conv2d(21, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (19): Conv2d(21, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (20): Conv2d(21, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): Conv2d(21, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (22): Conv2d(21, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (23): Conv2d(21, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (24): Conv2d(21, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): Conv2d(21, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (26): Conv2d(21, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (27): Conv2d(21, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): Conv2d(21, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (29): Conv2d(21, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (30): Conv2d(21, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): Conv2d(21, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (C): Linear(in_features=1344, out_features=10, bias=True)
)


		Parameters: 0.145183M
==> Resuming from checkpoint..
[IMPORTANT] Don't forget to rename the results object to not overwrite!! 
Current set up
Testing  False
[ALERT]: Path to results (this may overwrite ../results/dicts/ensemble_non_recursives/Ensemble_Non_Recursive_L_32_M_21_BN_False_K_8.pkl
[ALERT]: Path to checkpoint (this may overwrite ./checkpoint/Ensemble_Non_Recursive_L_32_M_21_BN_False_K_8.t7
Do you want to continue? [Y/n]: [OK]: Starting Training of Recursive Ensemble Model

Epoch: 230
Train :: Loss: 0.41 | Accy: 84.74
Valid :: Loss: 0.71 | Accy: 82.27
'run_epoch'  55765.11 ms

Epoch: 231
Train :: Loss: 0.53 | Accy: 84.58
Valid :: Loss: 0.52 | Accy: 81.39
'run_epoch'  55622.23 ms

Epoch: 232
Train :: Loss: 0.43 | Accy: 84.72
Valid :: Loss: 0.55 | Accy: 82.17
'run_epoch'  56678.44 ms

Epoch: 233
Train :: Loss: 0.54 | Accy: 84.61
Valid :: Loss: 0.6 | Accy: 82.61
Saving..
'run_epoch'  56160.65 ms

Epoch: 234
Train :: Loss: 0.4 | Accy: 84.66
Valid :: Loss: 0.5 | Accy: 82.2
'run_epoch'  56222.62 ms

Epoch: 235
Train :: Loss: 0.61 | Accy: 84.68
Valid :: Loss: 0.49 | Accy: 82.12
'run_epoch'  56505.44 ms

Epoch: 236
Train :: Loss: 0.45 | Accy: 84.64
Valid :: Loss: 0.61 | Accy: 82.22
'run_epoch'  56871.50 ms

Epoch: 237
Train :: Loss: 0.4 | Accy: 84.83
Valid :: Loss: 0.64 | Accy: 81.35
'run_epoch'  56448.38 ms

Epoch: 238
Train :: Loss: 0.39 | Accy: 84.89
Valid :: Loss: 0.61 | Accy: 82.34
'run_epoch'  56458.24 ms

Epoch: 239
Train :: Loss: 0.48 | Accy: 84.8
Valid :: Loss: 0.75 | Accy: 81.31
'run_epoch'  56070.42 ms

Epoch: 240
Train :: Loss: 0.51 | Accy: 84.78
Valid :: Loss: 0.63 | Accy: 81.97
'run_epoch'  56711.69 ms

Epoch: 241
Train :: Loss: 0.38 | Accy: 84.86
Valid :: Loss: 0.71 | Accy: 81.95
'run_epoch'  57025.88 ms

Epoch: 242
Train :: Loss: 0.49 | Accy: 84.82
Valid :: Loss: 0.58 | Accy: 82.5
'run_epoch'  56604.20 ms

Epoch: 243
Train :: Loss: 0.52 | Accy: 84.83
Valid :: Loss: 0.58 | Accy: 81.98
'run_epoch'  56759.29 ms

Epoch: 244
Train :: Loss: 0.44 | Accy: 84.87
Valid :: Loss: 0.55 | Accy: 82.37
'run_epoch'  56165.36 ms

Epoch: 245
Train :: Loss: 0.64 | Accy: 85.0
Valid :: Loss: 0.54 | Accy: 82.0
'run_epoch'  56915.71 ms

Epoch: 246
Train :: Loss: 0.45 | Accy: 84.85
Valid :: Loss: 0.56 | Accy: 82.39
'run_epoch'  56793.04 ms

Epoch: 247
Train :: Loss: 0.44 | Accy: 84.95
Valid :: Loss: 0.63 | Accy: 82.15
'run_epoch'  54643.15 ms

Epoch: 248
Train :: Loss: 0.55 | Accy: 84.88
Valid :: Loss: 0.64 | Accy: 82.55
'run_epoch'  56089.24 ms

Epoch: 249
Train :: Loss: 0.45 | Accy: 84.89
Valid :: Loss: 0.47 | Accy: 82.12
'run_epoch'  55885.63 ms

Epoch: 250
Train :: Loss: 0.45 | Accy: 85.0
Valid :: Loss: 0.58 | Accy: 82.7
Saving..
'run_epoch'  56619.16 ms

Epoch: 251
Train :: Loss: 0.41 | Accy: 84.89
Valid :: Loss: 0.52 | Accy: 82.27
'run_epoch'  55529.06 ms

Epoch: 252
Train :: Loss: 0.56 | Accy: 85.06
Valid :: Loss: 0.53 | Accy: 82.48
'run_epoch'  55080.49 ms

Epoch: 253
Train :: Loss: 0.31 | Accy: 85.03
Valid :: Loss: 0.56 | Accy: 82.46
'run_epoch'  55304.91 ms

Epoch: 254
Train :: Loss: 0.44 | Accy: 84.85
Valid :: Loss: 0.55 | Accy: 81.73
'run_epoch'  55308.21 ms

Epoch: 255
Train :: Loss: 0.45 | Accy: 85.06
Valid :: Loss: 0.65 | Accy: 82.13
'run_epoch'  55529.10 ms

Epoch: 256
Train :: Loss: 0.46 | Accy: 85.15
Valid :: Loss: 0.56 | Accy: 82.35
'run_epoch'  55744.19 ms

Epoch: 257
Train :: Loss: 0.58 | Accy: 85.09
Valid :: Loss: 0.63 | Accy: 81.95
'run_epoch'  54974.30 ms

Epoch: 258
Train :: Loss: 0.38 | Accy: 85.25
Valid :: Loss: 0.54 | Accy: 82.1
'run_epoch'  55462.19 ms

Epoch: 259
Train :: Loss: 0.47 | Accy: 85.12
Valid :: Loss: 0.62 | Accy: 81.83
'run_epoch'  55189.29 ms

Epoch: 260
Train :: Loss: 0.41 | Accy: 85.09
Valid :: Loss: 0.54 | Accy: 82.3
'run_epoch'  55863.25 ms

Epoch: 261
Train :: Loss: 0.38 | Accy: 85.13
Valid :: Loss: 0.63 | Accy: 82.38
'run_epoch'  55546.69 ms

Epoch: 262
Train :: Loss: 0.51 | Accy: 85.33
Valid :: Loss: 0.56 | Accy: 82.79
Saving..
'run_epoch'  54659.06 ms

Epoch: 263
Train :: Loss: 0.45 | Accy: 85.3
Valid :: Loss: 0.65 | Accy: 82.45
'run_epoch'  54834.29 ms

Epoch: 264
Train :: Loss: 0.36 | Accy: 85.03
Valid :: Loss: 0.62 | Accy: 82.81
Saving..
'run_epoch'  55444.74 ms

Epoch: 265
Train :: Loss: 0.38 | Accy: 85.31
Valid :: Loss: 0.59 | Accy: 82.28
'run_epoch'  55328.22 ms

Epoch: 266
Train :: Loss: 0.46 | Accy: 85.32
Valid :: Loss: 0.58 | Accy: 82.51
'run_epoch'  56396.74 ms

Epoch: 267
Train :: Loss: 0.37 | Accy: 85.29
Valid :: Loss: 0.55 | Accy: 82.7
'run_epoch'  57223.94 ms

Epoch: 268
Train :: Loss: 0.35 | Accy: 85.33
Valid :: Loss: 0.66 | Accy: 82.39
'run_epoch'  56752.00 ms

Epoch: 269
Train :: Loss: 0.46 | Accy: 85.31
Valid :: Loss: 0.52 | Accy: 82.47
'run_epoch'  55494.72 ms

Epoch: 270
Train :: Loss: 0.39 | Accy: 85.09
Valid :: Loss: 0.66 | Accy: 82.81
'run_epoch'  56293.79 ms

Epoch: 271
Train :: Loss: 0.55 | Accy: 85.47
Valid :: Loss: 0.73 | Accy: 82.5
'run_epoch'  56859.43 ms

Epoch: 272
Train :: Loss: 0.45 | Accy: 85.21
Valid :: Loss: 0.72 | Accy: 82.05
'run_epoch'  56159.38 ms

Epoch: 273
Train :: Loss: 0.59 | Accy: 85.27
Valid :: Loss: 0.72 | Accy: 82.07
'run_epoch'  55853.67 ms

Epoch: 274
Train :: Loss: 0.4 | Accy: 85.34
Valid :: Loss: 0.67 | Accy: 82.21
'run_epoch'  55726.03 ms

Epoch: 275
Train :: Loss: 0.49 | Accy: 85.22
Valid :: Loss: 0.64 | Accy: 82.5
'run_epoch'  56285.70 ms

Epoch: 276
Train :: Loss: 0.31 | Accy: 85.44
Valid :: Loss: 0.51 | Accy: 82.52
'run_epoch'  56829.88 ms

Epoch: 277
Train :: Loss: 0.47 | Accy: 85.38
Valid :: Loss: 0.63 | Accy: 82.3
'run_epoch'  56179.97 ms

Epoch: 278
Train :: Loss: 0.29 | Accy: 85.53
Valid :: Loss: 0.59 | Accy: 82.8
'run_epoch'  57517.24 ms

Epoch: 279
Train :: Loss: 0.53 | Accy: 85.4
Valid :: Loss: 0.56 | Accy: 82.4
'run_epoch'  57242.63 ms

Epoch: 280
Train :: Loss: 0.5 | Accy: 85.47
Valid :: Loss: 0.62 | Accy: 82.15
'run_epoch'  57616.42 ms

Epoch: 281
Train :: Loss: 0.35 | Accy: 85.52
Valid :: Loss: 0.76 | Accy: 82.21
'run_epoch'  56272.41 ms

Epoch: 282
Train :: Loss: 0.36 | Accy: 85.46
Valid :: Loss: 0.54 | Accy: 83.12
Saving..
'run_epoch'  56226.64 ms

Epoch: 283
Train :: Loss: 0.54 | Accy: 85.34
Valid :: Loss: 0.63 | Accy: 82.66
'run_epoch'  56322.95 ms

Epoch: 284
Train :: Loss: 0.36 | Accy: 85.4
Valid :: Loss: 0.54 | Accy: 82.41
'run_epoch'  57615.47 ms

Epoch: 285
Train :: Loss: 0.52 | Accy: 85.48
Valid :: Loss: 0.66 | Accy: 82.67
'run_epoch'  56324.10 ms

Epoch: 286
Train :: Loss: 0.32 | Accy: 85.63
Valid :: Loss: 0.71 | Accy: 83.13
Saving..
'run_epoch'  56769.22 ms

Epoch: 287
Train :: Loss: 0.44 | Accy: 85.41
Valid :: Loss: 0.53 | Accy: 82.63
'run_epoch'  55866.03 ms

Epoch: 288
Train :: Loss: 0.55 | Accy: 85.41
Valid :: Loss: 0.63 | Accy: 82.63
'run_epoch'  57183.62 ms

Epoch: 289
Train :: Loss: 0.3 | Accy: 85.37
Valid :: Loss: 0.62 | Accy: 82.34
'run_epoch'  55322.76 ms

Epoch: 290
Train :: Loss: 0.46 | Accy: 85.48
Valid :: Loss: 0.52 | Accy: 82.98
'run_epoch'  56383.80 ms

Epoch: 291
Train :: Loss: 0.49 | Accy: 85.69
Valid :: Loss: 0.56 | Accy: 82.94
'run_epoch'  56571.51 ms

Epoch: 292
Train :: Loss: 0.37 | Accy: 85.49
Valid :: Loss: 0.56 | Accy: 82.62
'run_epoch'  56275.90 ms

Epoch: 293
Train :: Loss: 0.53 | Accy: 85.54
Valid :: Loss: 0.64 | Accy: 82.65
'run_epoch'  55833.39 ms

Epoch: 294
Train :: Loss: 0.39 | Accy: 85.64
Valid :: Loss: 0.61 | Accy: 82.76
'run_epoch'  56393.88 ms

Epoch: 295
Train :: Loss: 0.4 | Accy: 85.49
Valid :: Loss: 0.55 | Accy: 83.04
'run_epoch'  57092.64 ms

Epoch: 296
Train :: Loss: 0.36 | Accy: 85.7
Valid :: Loss: 0.71 | Accy: 82.89
'run_epoch'  55754.82 ms

Epoch: 297
Train :: Loss: 0.44 | Accy: 85.67
Valid :: Loss: 0.71 | Accy: 82.69
'run_epoch'  55813.74 ms

Epoch: 298
Train :: Loss: 0.58 | Accy: 85.74
Valid :: Loss: 0.61 | Accy: 82.29
'run_epoch'  56691.03 ms

Epoch: 299
Train :: Loss: 0.31 | Accy: 85.5
Valid :: Loss: 0.7 | Accy: 82.69
'run_epoch'  56661.72 ms

Epoch: 300
Train :: Loss: 0.51 | Accy: 85.6
Valid :: Loss: 0.61 | Accy: 82.68
'run_epoch'  56435.19 ms

Epoch: 301
Train :: Loss: 0.45 | Accy: 85.6
Valid :: Loss: 0.59 | Accy: 82.79
'run_epoch'  56665.04 ms

Epoch: 302
Train :: Loss: 0.46 | Accy: 85.6
Valid :: Loss: 0.57 | Accy: 82.97
'run_epoch'  56967.61 ms

Epoch: 303
Train :: Loss: 0.37 | Accy: 85.76
Valid :: Loss: 0.48 | Accy: 82.93
'run_epoch'  56434.73 ms

Epoch: 304
Train :: Loss: 0.43 | Accy: 85.59
Valid :: Loss: 0.55 | Accy: 82.89
'run_epoch'  56290.50 ms

Epoch: 305
Train :: Loss: 0.47 | Accy: 85.61
Valid :: Loss: 0.67 | Accy: 82.92
'run_epoch'  55620.90 ms

Epoch: 306
Train :: Loss: 0.47 | Accy: 85.59
Valid :: Loss: 0.77 | Accy: 82.47
'run_epoch'  56512.34 ms

Epoch: 307
Train :: Loss: 0.48 | Accy: 85.68
Valid :: Loss: 0.53 | Accy: 82.61
'run_epoch'  56584.45 ms

Epoch: 308
Train :: Loss: 0.54 | Accy: 85.74
Valid :: Loss: 0.51 | Accy: 82.56
'run_epoch'  56100.73 ms

Epoch: 309
Train :: Loss: 0.49 | Accy: 85.77
Valid :: Loss: 0.6 | Accy: 82.79
'run_epoch'  56533.14 ms

Epoch: 310
Train :: Loss: 0.46 | Accy: 85.76
Valid :: Loss: 0.64 | Accy: 82.58
'run_epoch'  56128.86 ms

Epoch: 311
Train :: Loss: 0.48 | Accy: 85.88
Valid :: Loss: 0.56 | Accy: 82.85
'run_epoch'  57496.65 ms

Epoch: 312
Train :: Loss: 0.36 | Accy: 85.62
Valid :: Loss: 0.47 | Accy: 82.68
'run_epoch'  56080.21 ms

Epoch: 313
Train :: Loss: 0.45 | Accy: 85.87
Valid :: Loss: 0.57 | Accy: 82.76
'run_epoch'  55452.17 ms

Epoch: 314
Train :: Loss: 0.4 | Accy: 85.57
Valid :: Loss: 0.65 | Accy: 82.82
'run_epoch'  56572.57 ms

Epoch: 315
Train :: Loss: 0.33 | Accy: 85.86
Valid :: Loss: 0.59 | Accy: 83.04
'run_epoch'  55963.29 ms

Epoch: 316
Train :: Loss: 0.35 | Accy: 85.9
Valid :: Loss: 0.58 | Accy: 83.07
'run_epoch'  57063.49 ms

Epoch: 317
Train :: Loss: 0.5 | Accy: 85.89
Valid :: Loss: 0.64 | Accy: 82.64
'run_epoch'  56824.12 ms

Epoch: 318
Train :: Loss: 0.37 | Accy: 85.76
Valid :: Loss: 0.6 | Accy: 82.99
'run_epoch'  57075.68 ms

Epoch: 319
Train :: Loss: 0.39 | Accy: 85.79
Valid :: Loss: 0.56 | Accy: 83.24
Saving..
'run_epoch'  56614.22 ms

Epoch: 320
Train :: Loss: 0.41 | Accy: 85.9
Valid :: Loss: 0.6 | Accy: 83.0
'run_epoch'  57968.49 ms

Epoch: 321
Train :: Loss: 0.43 | Accy: 86.06
Valid :: Loss: 0.64 | Accy: 83.0
'run_epoch'  56044.34 ms

Epoch: 322
Train :: Loss: 0.41 | Accy: 85.93
Valid :: Loss: 0.57 | Accy: 82.53
'run_epoch'  56387.51 ms

Epoch: 323
Train :: Loss: 0.49 | Accy: 85.97
Valid :: Loss: 0.52 | Accy: 82.96
'run_epoch'  56150.90 ms

Epoch: 324
Train :: Loss: 0.56 | Accy: 85.84
Valid :: Loss: 0.58 | Accy: 82.67
'run_epoch'  55769.37 ms

Epoch: 325
Train :: Loss: 0.28 | Accy: 85.99
Valid :: Loss: 0.52 | Accy: 82.9
'run_epoch'  57404.26 ms

Epoch: 326
Train :: Loss: 0.36 | Accy: 85.83
Valid :: Loss: 0.52 | Accy: 82.85
'run_epoch'  56413.64 ms

Epoch: 327
Train :: Loss: 0.36 | Accy: 86.07
Valid :: Loss: 0.65 | Accy: 83.24
'run_epoch'  56779.75 ms

Epoch: 328
Train :: Loss: 0.31 | Accy: 85.81
Valid :: Loss: 0.53 | Accy: 83.43
Saving..
'run_epoch'  56127.58 ms

Epoch: 329
Train :: Loss: 0.32 | Accy: 86.12
Valid :: Loss: 0.55 | Accy: 83.21
'run_epoch'  56272.20 ms

Epoch: 330
Train :: Loss: 0.36 | Accy: 85.85
Valid :: Loss: 0.59 | Accy: 82.83
'run_epoch'  56060.95 ms

Epoch: 331
Train :: Loss: 0.39 | Accy: 86.02
Valid :: Loss: 0.56 | Accy: 83.07
'run_epoch'  55868.57 ms

Epoch: 332
Train :: Loss: 0.28 | Accy: 85.87
Valid :: Loss: 0.63 | Accy: 82.41
'run_epoch'  56056.76 ms

Epoch: 333
Train :: Loss: 0.28 | Accy: 85.97
Valid :: Loss: 0.56 | Accy: 82.98
'run_epoch'  56133.70 ms

Epoch: 334
Train :: Loss: 0.4 | Accy: 86.13
Valid :: Loss: 0.47 | Accy: 82.45
'run_epoch'  56070.11 ms

Epoch: 335
Train :: Loss: 0.42 | Accy: 86.12
Valid :: Loss: 0.53 | Accy: 83.19
'run_epoch'  55851.01 ms

Epoch: 336
Train :: Loss: 0.43 | Accy: 85.93
Valid :: Loss: 0.58 | Accy: 82.76
'run_epoch'  56489.38 ms

Epoch: 337
Train :: Loss: 0.44 | Accy: 85.96
Valid :: Loss: 0.52 | Accy: 83.42
'run_epoch'  56745.00 ms

Epoch: 338
Train :: Loss: 0.42 | Accy: 85.96
Valid :: Loss: 0.6 | Accy: 82.65
'run_epoch'  56630.91 ms

Epoch: 339
Train :: Loss: 0.47 | Accy: 86.19
Valid :: Loss: 0.6 | Accy: 83.04
'run_epoch'  58115.39 ms

Epoch: 340
Train :: Loss: 0.3 | Accy: 86.15
Valid :: Loss: 0.68 | Accy: 83.05
'run_epoch'  57688.67 ms

Epoch: 341
Train :: Loss: 0.4 | Accy: 86.14
Valid :: Loss: 0.55 | Accy: 83.22
'run_epoch'  57367.55 ms

Epoch: 342
Train :: Loss: 0.48 | Accy: 86.06
Valid :: Loss: 0.6 | Accy: 82.72
'run_epoch'  55797.57 ms

Epoch: 343
Train :: Loss: 0.54 | Accy: 86.2
Valid :: Loss: 0.53 | Accy: 83.44
Saving..
'run_epoch'  56560.20 ms

Epoch: 344
Train :: Loss: 0.59 | Accy: 86.31
Valid :: Loss: 0.58 | Accy: 83.34
'run_epoch'  56434.48 ms

Epoch: 345
Train :: Loss: 0.4 | Accy: 86.2
Valid :: Loss: 0.66 | Accy: 83.19
'run_epoch'  56908.08 ms

Epoch: 346
Train :: Loss: 0.5 | Accy: 86.16
Valid :: Loss: 0.58 | Accy: 83.0
'run_epoch'  56318.91 ms

Epoch: 347
Train :: Loss: 0.46 | Accy: 86.44
Valid :: Loss: 0.57 | Accy: 83.14
'run_epoch'  56400.24 ms

Epoch: 348
Train :: Loss: 0.46 | Accy: 86.14
Valid :: Loss: 0.54 | Accy: 83.14
'run_epoch'  58257.10 ms

Epoch: 349
Train :: Loss: 0.54 | Accy: 86.2
Valid :: Loss: 0.56 | Accy: 83.0
'run_epoch'  59425.14 ms

Epoch: 350
Train :: Loss: 0.31 | Accy: 86.22
Valid :: Loss: 0.49 | Accy: 83.44
'run_epoch'  57860.72 ms

Epoch: 351
Train :: Loss: 0.3 | Accy: 86.25
Valid :: Loss: 0.54 | Accy: 83.33
'run_epoch'  57821.66 ms

Epoch: 352
Train :: Loss: 0.32 | Accy: 86.16
Valid :: Loss: 0.56 | Accy: 83.1
'run_epoch'  58012.56 ms

Epoch: 353
Train :: Loss: 0.45 | Accy: 86.08
Valid :: Loss: 0.62 | Accy: 82.77
'run_epoch'  56700.07 ms

Epoch: 354
Train :: Loss: 0.44 | Accy: 86.23
Valid :: Loss: 0.48 | Accy: 83.15
'run_epoch'  56928.47 ms

Epoch: 355
Train :: Loss: 0.39 | Accy: 86.35
Valid :: Loss: 0.5 | Accy: 83.31
'run_epoch'  56714.42 ms

Epoch: 356
Train :: Loss: 0.37 | Accy: 86.19
Valid :: Loss: 0.56 | Accy: 82.84
'run_epoch'  57670.46 ms

Epoch: 357
Train :: Loss: 0.25 | Accy: 86.28
Valid :: Loss: 0.61 | Accy: 83.25
'run_epoch'  56086.12 ms

Epoch: 358
Train :: Loss: 0.42 | Accy: 86.29
Valid :: Loss: 0.51 | Accy: 82.5
'run_epoch'  55871.14 ms

Epoch: 359
Train :: Loss: 0.32 | Accy: 86.23
Valid :: Loss: 0.61 | Accy: 83.09
'run_epoch'  56188.87 ms

Epoch: 360
Train :: Loss: 0.46 | Accy: 86.42
Valid :: Loss: 0.6 | Accy: 83.4
'run_epoch'  56551.49 ms

Epoch: 361
Train :: Loss: 0.42 | Accy: 86.17
Valid :: Loss: 0.61 | Accy: 82.94
'run_epoch'  55755.31 ms

Epoch: 362
Train :: Loss: 0.52 | Accy: 86.3
Valid :: Loss: 0.61 | Accy: 83.16
'run_epoch'  56373.98 ms

Epoch: 363
Train :: Loss: 0.28 | Accy: 86.33
Valid :: Loss: 0.55 | Accy: 83.17
'run_epoch'  56400.42 ms

Epoch: 364
Train :: Loss: 0.41 | Accy: 86.43
Valid :: Loss: 0.58 | Accy: 83.48
Saving..
'run_epoch'  56632.46 ms

Epoch: 365
Train :: Loss: 0.43 | Accy: 86.23
Valid :: Loss: 0.65 | Accy: 83.09
'run_epoch'  56050.97 ms

Epoch: 366
Train :: Loss: 0.39 | Accy: 86.32
Valid :: Loss: 0.72 | Accy: 82.9
'run_epoch'  55486.51 ms

Epoch: 367
Train :: Loss: 0.57 | Accy: 86.41
Valid :: Loss: 0.72 | Accy: 82.86
'run_epoch'  55829.15 ms

Epoch: 368
Train :: Loss: 0.39 | Accy: 86.25
Valid :: Loss: 0.52 | Accy: 83.15
'run_epoch'  57046.74 ms

Epoch: 369
Train :: Loss: 0.48 | Accy: 86.23
Valid :: Loss: 0.57 | Accy: 83.13
'run_epoch'  57006.36 ms

Epoch: 370
Train :: Loss: 0.34 | Accy: 86.49
Valid :: Loss: 0.63 | Accy: 83.06
'run_epoch'  56307.82 ms

Epoch: 371
Train :: Loss: 0.48 | Accy: 86.5
Valid :: Loss: 0.55 | Accy: 83.18
'run_epoch'  57013.07 ms

Epoch: 372
Train :: Loss: 0.37 | Accy: 86.38
Valid :: Loss: 0.57 | Accy: 83.16
'run_epoch'  56340.61 ms

Epoch: 373
Train :: Loss: 0.4 | Accy: 86.37
Valid :: Loss: 0.62 | Accy: 83.6
Saving..
'run_epoch'  57471.35 ms

Epoch: 374
Train :: Loss: 0.38 | Accy: 86.33
Valid :: Loss: 0.57 | Accy: 83.4
'run_epoch'  56107.88 ms

Epoch: 375
Train :: Loss: 0.37 | Accy: 86.43
Valid :: Loss: 0.57 | Accy: 83.34
'run_epoch'  56304.09 ms

Epoch: 376
Train :: Loss: 0.38 | Accy: 86.45
Valid :: Loss: 0.55 | Accy: 83.01
'run_epoch'  56630.63 ms

Epoch: 377
Train :: Loss: 0.37 | Accy: 86.48
Valid :: Loss: 0.6 | Accy: 83.08
'run_epoch'  55773.25 ms

Epoch: 378
Train :: Loss: 0.37 | Accy: 86.38
Valid :: Loss: 0.63 | Accy: 82.78
'run_epoch'  56064.60 ms

Epoch: 379
Train :: Loss: 0.32 | Accy: 86.49
Valid :: Loss: 0.58 | Accy: 83.38
'run_epoch'  57043.72 ms

Epoch: 380
Train :: Loss: 0.44 | Accy: 86.48
Valid :: Loss: 0.54 | Accy: 83.19
'run_epoch'  56201.62 ms

Epoch: 381
Train :: Loss: 0.39 | Accy: 86.45
Valid :: Loss: 0.54 | Accy: 83.11
'run_epoch'  55740.95 ms

Epoch: 382
Train :: Loss: 0.55 | Accy: 86.4
Valid :: Loss: 0.56 | Accy: 83.74
Saving..
'run_epoch'  55676.86 ms

Epoch: 383
Train :: Loss: 0.32 | Accy: 86.64
Valid :: Loss: 0.53 | Accy: 83.53
'run_epoch'  56081.88 ms

Epoch: 384
Train :: Loss: 0.4 | Accy: 86.44
Valid :: Loss: 0.48 | Accy: 83.2
'run_epoch'  55509.77 ms

Epoch: 385
Train :: Loss: 0.47 | Accy: 86.49
Valid :: Loss: 0.52 | Accy: 83.19
'run_epoch'  56360.20 ms

Epoch: 386
Train :: Loss: 0.51 | Accy: 86.53
Valid :: Loss: 0.58 | Accy: 83.26
'run_epoch'  55544.88 ms

Epoch: 387
Train :: Loss: 0.49 | Accy: 86.51
Valid :: Loss: 0.62 | Accy: 83.28
'run_epoch'  56097.96 ms

Epoch: 388
Train :: Loss: 0.34 | Accy: 86.73
Valid :: Loss: 0.59 | Accy: 83.53
'run_epoch'  56558.90 ms

Epoch: 389
Train :: Loss: 0.36 | Accy: 86.56
Valid :: Loss: 0.58 | Accy: 83.65
'run_epoch'  56610.33 ms

Epoch: 390
Train :: Loss: 0.44 | Accy: 86.6
Valid :: Loss: 0.61 | Accy: 83.12
'run_epoch'  56031.37 ms

Epoch: 391
Train :: Loss: 0.35 | Accy: 86.65
Valid :: Loss: 0.61 | Accy: 83.08
'run_epoch'  56566.62 ms

Epoch: 392
Train :: Loss: 0.35 | Accy: 86.69
Valid :: Loss: 0.61 | Accy: 83.42
'run_epoch'  56838.29 ms

Epoch: 393
Train :: Loss: 0.42 | Accy: 86.7
Valid :: Loss: 0.53 | Accy: 83.25
'run_epoch'  56493.71 ms

Epoch: 394
Train :: Loss: 0.35 | Accy: 86.45
Valid :: Loss: 0.63 | Accy: 83.58
'run_epoch'  56393.56 ms

Epoch: 395
Train :: Loss: 0.47 | Accy: 86.54
Valid :: Loss: 0.58 | Accy: 83.19
'run_epoch'  55813.02 ms

Epoch: 396
Train :: Loss: 0.34 | Accy: 86.66
Valid :: Loss: 0.65 | Accy: 83.44
'run_epoch'  58029.46 ms

Epoch: 397
Train :: Loss: 0.49 | Accy: 86.47
Valid :: Loss: 0.64 | Accy: 83.42
'run_epoch'  56782.77 ms

Epoch: 398
Train :: Loss: 0.38 | Accy: 86.6
Valid :: Loss: 0.52 | Accy: 83.21
'run_epoch'  57415.73 ms

Epoch: 399
Train :: Loss: 0.36 | Accy: 86.51
Valid :: Loss: 0.52 | Accy: 83.65
'run_epoch'  57113.32 ms

Epoch: 400
